---
title: Problem set 6
date: 2025-03-02
execute: 
  eval: false
---

For this problem set we want you to predict the 2024 election. You you will report a prediction of the number of electoral votes for Harris and an interval. You will do the same for the popular vote. You will compare your accuracy to the true results.

1. Read in the data provided here:

```{r}
url <- "https://raw.githubusercontent.com/dmcable/BIOSTAT620/refs/heads/main/data/president_polls.csv"
```

Examine the data frame paying particular attention to the `poll_id` `question_id`, `population`, and `candidate`. Note that some polls have more than one question based on different population types.

```{r}
library(tidyverse)
library(rvest)

raw_dat <- read_csv(url)
glimpse(raw_dat)
colnames(raw_dat)
raw_dat |> select(poll_id, question_id, population, candidate_id)
```

2. Polls are based on either likely voters (lv), registered voters (rv), all voters (a), or voters (v).
Polls based on 'voters' are exit polls. We want to remove these because exit polls are too old or might be biased due to differences in the likelihood of early voter by party.  We prefer likely voter (lv) polls because they are more predictive. Registered voter polls are more predictive than all voter (a) polls. Remove the exit poll (v) polls and then redefine `population` to be a factor ordered from best to worse predictive power: (lv, rv, a). You should also remove hypothetical polls and make the date columns into date objects. Name the resulting data frame `dat`.

```{r}
dat <- raw_dat |> 
  ## Your code here
  filter(population != "v") |>
  mutate(population = factor(population, levels = c("lv", "rv", "a"), ordered = TRUE)) |>
  filter(is.na(hypothetical) | !hypothetical) |>
  mutate(
    start_date = mdy(start_date),
    end_date = mdy(end_date),
    election_date = mdy(election_date))
head(dat) 
```


3. Some polls asked more than one questions. So if you filter to one poll ID in our dataset, you might see more than one question ID associated with the same poll. The most common reason for this is that they asked a head-to-head question (Harris versus Trump) and, in the same poll, a question about all candidates. We want to prioritize the head-to-head questions.

Add a column that tells us, for each question, how many candidates where mentioned in that question.

Add a new column `n` to `dat` that provides the number of candidates mentioned for each question.  For example
the relevant column of your final table will looks something like this:

|`poll_id`|`question_id`|`candidate`|`n`|
---------|-------------|-----------|--|
1 | 1 | Harris | 2 |
1 | 1 | Trump | 2 |
1 | 2 | Harris | 3 |
1 | 2 | Trump |  3 |
1 | 2 | Stein |3 |

```{r}
dat <- dat |> 
    ## Your code here
  group_by(poll_id) |> 
  filter(n_distinct(question_id) > 1) |> 
  ungroup() |> 
  group_by(question_id) |>
  mutate(
    candidate = word(candidate_name, -1),
    n = n_distinct(candidate_name))|>
  ungroup() |>
  arrange(poll_id) |> 
  mutate(poll_id = dense_rank(poll_id)) |>  
  group_by(poll_id) |> 
  arrange(question_id, .by_group = TRUE) |> 
  mutate(question_id = dense_rank(question_id)) |>  
  ungroup() |> 
  group_by(question_id) |> 
  filter(n == 2 | (!any(n == 2) & n > 2)) |>
  ungroup()

head(dat)
```


4. We are going to focus on the Harris versus Trump comparison. Redefine `dat` to only include the rows providing information for Harris and Trump. Then pivot the dataset so that the percentages for Harris and Trump are in their own columns. Note that for pivot to work you will have to remove some columns. To avoid this keep only the columns you are pivoting and along with `poll_id`, `question_id`, `state`, `pollster`, `start_date`, `end_date`, `numeric_grade`, `sample_size`.  Once you accomplish the pivot, add a column called `spread` with the difference between Harris and Trump. 

Note that the values stored in `spread` are estimates of the popular vote difference that we will use to predict: 

**spread = % of the popular vote for Harris - % of the popular vote for Trump**

However, for the calculations in the rest of problem set to be consistent with the sampling model we have been discussing in class, save `spread` as a proportion, not a percentage. But remember to turn it back to a percentage when reporting your answer.

```{r}
dat <- dat |>
  ## Your code here
  filter(candidate_name %in% c("Kamala Harris", "Donald Trump")) |>
  select(candidate_name, pct, poll_id, question_id, state, pollster, population, start_date, end_date, numeric_grade, sample_size) |>
  pivot_wider(names_from = candidate_name, values_from = pct) |>
  mutate(spread = (`Kamala Harris` - `Donald Trump`) / 100)
head(dat)
```

5. Note that some polls have multiple questions. We want to keep only one question per poll. We will keep likely voter (lv) polls when available, and prefer register voter (rv) over all voter polls (a). If more than one question was asked in one poll, take the most targeted question (smallest `n`). Save the resulting table`dat`. Note that now each after you do this each row will represents exactly one poll/question, so can remove `n`, `poll_id` and `question_id`.

```{r}
dat <- dat |> 
  mutate(population = factor(population, levels = c("lv", "rv", "a"), ordered = TRUE)) |>
  group_by(poll_id) |>
  arrange(population, n, .by_group = TRUE) |>
  slice(1) |>
  ungroup() |>
  select(-c(poll_id, question_id))
head(dat)
```

6. Separate `dat` into two data frames: one with popular vote polls and one with state level polls. Call them `popular_vote` and `polls` respectively. 

```{r}
popular_vote <- dat |> filter(is.na(state))
polls <- dat |> filter(!is.na(state))

head(popular_vote)
head(polls)
```

7. For the popular vote, plot the spread reported by each poll against start date for polls starting after July 21, 2024. Rename all the pollsters with less than 5 polls during this period as `Other`. Use color to denote pollster. Make separate plots for likely voters and registered voters. Do not use _all voter_ polls (a). Use `geom_smooth` with method `loess` to show a curve going through the points. You can change how adaptive the curve is to that through the `span` argument.

```{r}
popular_dat <- popular_vote |> 
  filter(start_date > make_date(2024, 7, 21) & population != "a") |>
  ### Your code here
  group_by(pollster) |> 
  mutate(n = n()) |>
  ungroup() |>  
  mutate(pollster = ifelse(n < 5, "Other", pollster)) |> 
  select(-n) 

ggplot(popular_dat, aes(x = start_date, y = spread, color = pollster)) +
  geom_point(alpha = 0.5) + 
  geom_smooth(method = "loess", span = 0.7) + 
  facet_wrap(~population) + 
  labs(title = "Popular Vote Spread Over Time",
       x = "Start Date", y = "Spread (Harris - Trump)",
       color = "Pollster") +
  theme_classic()
```


8. To show the pollster effect, make boxplots for the the spread for each popular vote poll. Include only likely voter polls starting after July 21, 2024. Rename all the pollsters with less than 5 polls during that time period as `Other`. 

```{r}
popular_dat <- popular_vote |> 
  filter(start_date > make_date(2024, 7, 21) & population == "lv") |>
  ### Your code here
  group_by(pollster) |> 
  mutate(n = n()) |>
  ungroup() |>  
  mutate(pollster = ifelse(n < 5, "Other", pollster)) |> 
  select(-n) 

ggplot(popular_dat, aes(x = fct_reorder(pollster, spread), y = spread, fill = pollster)) +
  geom_boxplot() + 
  labs(title = "Pollster Effect on Spread (Likely Voters)",
       x = "Pollster", y = "Spread (Harris - Trump)") + theme_classic()
```

9. Compute a prediction and an interval and report the result. Include the code you used to create your confidence interval for the popular vote here:

```{r}
## Your code here
spread_sum <- popular_vote |>
  summarise(
    mean_spread = mean(spread, na.rm = TRUE),
    sd_spread = sd(spread, na.rm = TRUE),
    n = n()
  ) |>
  mutate(
    se = sd_spread / sqrt(n),
    L_CI = mean_spread - 1.96 * se,
    U_CI = mean_spread + 1.96 * se
  )
print(spread_sum)
```

Harris received a popular vote spread of `-1.5%` vs Trump in the 2024 election. How did your model do? Provide some potential explanations for the performance.

```
YOUR SHORT ANSWER HERE
The model overestimated Harris's support, predicting a spread of +0.93%, while the actual result was -1.5%. The prediction interval [0.39%, 1.5%] did not cover the true result, indicating a significant bias. This discrepancy likely comes from polling errors, last-minute voter shifts, and turnout differences. Future models could improve by incorporating more swing state data and late-breaking trends.
```

We now move on to predicting the electoral votes.

10. To obtain the number of electoral votes for each state we will visit this website:

```{r}
url <- "https://state.1keydata.com/state-electoral-votes.php"
```

We can use the **rvest** package to download and extract the relevant table:

```{r}
library(rvest)
h <- read_html(url) |>
  html_table() 

ev <- h[[4]]
```

Wrangle the data in `ev` to only have two columns `state` and `electoral_votes`. Make sure the electoral vote column is numeric. Add the electoral votes for Maine CD-1 (1), Maine CD-2 (1), Nebraska CD-2 (1), and District of Columbia (3) by hand. 

```{r}
### Your code here
ev <- ev |>
  select(state = X2, electoral_votes = X3) |>
  filter(state != "State Name" & electoral_votes != "Number of Electoral Votes") |>
  mutate(electoral_votes = as.numeric(electoral_votes))

extra_votes <- tibble(
  state = c("Maine CD-1", "Maine CD-2", "Nebraska CD-2", "District of Columbia"),
  electoral_votes = c(1, 1, 1, 3)
)

ev <- bind_rows(ev, extra_votes)
print(ev)
```

11. The presidential race in some states is a forgone conclusion. Because their is practically no uncertainty in who will win, polls are not taken. We will therefore assume that the party that won in 2020 will win again in 2024 if no polls are being collected for a state.

Download the following sheet:

```{r}
library(gsheet)
sheet_url <- "https://docs.google.com/spreadsheets/d/1D-edaVHTnZNhVU840EPUhz3Cgd7m39Urx7HM8Pq6Pus/edit?gid=29622862"
raw_res_2020 <- gsheet2tbl(sheet_url) 
```

Tidy the `raw_res_2020` dataset so that you have two columns `state` and `party`, with `D` and `R` in the party column to indicate who won in 2020. Add Maine CD-1 (D), Maine CD-2 (R), Nebraska CD-2 (D), and District of Columbia (D) by hand. Save the result to `res_2020`. Hint use the **janitor** `row_to_names` function.

```{r}
library(janitor)
res_2020 <- raw_res_2020[,c(1,4)] |>  
 ### Your code here
  row_to_names(row_number = 1) |>
  select(state = State, party = `P.S.`) |>
  filter(state != "Nationwide") |>
  mutate(party = case_when(
    grepl("D", party) ~ "D",
    grepl("R", party) ~ "R",
    TRUE ~ NA_character_
  )) |>
  drop_na()

extra_states <- tibble(
  state = c("Maine CD-1", "Maine CD-2", "Nebraska CD-2", "District of Columbia"),
  party = c("D", "R", "D", "D")
)

res_2020 <- bind_rows(res_2020, extra_states)
res_2020
```

12. Decide on a period that you will use to compute your prediction. We will use `spread` as the outcome. Make sure the the outcomes is saved as a proportion not percentage. Create a `results` data frame with columns `state`, `avg`, `sd`, `n` and `electoral_votes`, with one row per state. 

Some ideas and recommendations:

* If a state has enough polls, consider a short period, such as a week. For states with few polls you might need to increase the interval to increase the number of polls.
* Decide which polls to prioritize based on the `population` and `numeric_grade` columns.
* You might want to weigh them differently, in which you might also consider using `sample_size`.
* If you use fewer than 5 polls to calculate an average, your estimate of the standard deviation (SD) may be unreliable. With only one poll, you wont be able to estimate the SD at all. In these cases, consider using the SD from similar states to avoid unusual or inaccurate estimates.


```{r}
results <- polls |> 
  group_by(state) |> 
  summarize(
    avg = mean(spread, na.rm = TRUE),
    sd = sd(spread, na.rm = TRUE),
    n = n(),
    numeric_grade = first(numeric_grade),
    .groups = "drop"
  ) |> 
  left_join(ev |> select(state, electoral_votes), by = "state") |>
  group_by(numeric_grade) |> 
  mutate(sd = ifelse(n < 5, mean(sd, na.rm = TRUE), sd)) |> 
  ungroup() |>
  mutate(sd = ifelse(is.na(sd), mean(sd, na.rm = TRUE), sd))|>
  select(state, avg, sd, n, electoral_votes)

print(results)
```


13. Note you will not have polls for all states. Assume that lack of polls implies the state is not in play.
Use the `res_2020` data frame to compute the electoral votes Harris is practically guaranteed to have.

```{r}
harris_start <- res_2020 |>
  filter(party == "D") |>
  left_join(ev, by = "state") |>
  summarise(total_ev = sum(electoral_votes, na.rm = TRUE))
harris_start
```


14. Use a Bayesian approach to compute posterior means and standard deviations for each state in `results`. Plot the posterior mean versus the observed average with the size of the point proportional to the number of polls.

```{r}
theta <- mean(results$avg, na.rm = TRUE)
tau <- sd(results$avg, na.rm = TRUE)
B <- (results$sd^2 / results$n) / ((results$sd^2 / results$n) + tau^2)

results <- results |>
  mutate(
    post_mean <- B*theta + (1-B)*(results$avg),
    post_sd <- sqrt(1 / (results$n / results$sd^2 + 1 / tau^2))
  )

ggplot(results, aes(x = avg, y = post_mean, size = n)) +
  geom_point(alpha = 0.6) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") +
  labs(title = "Posterior Mean vs Observed Average",
       x = "Observed Average Spread",
       y = "Posterior Mean",
       size = "Number of Polls") +
  theme_classic()
```


15. Compute a prediction and an interval for Harris' electoral votes and show the result. Include the code you used to create your estimate and interval below. 

```{r}
harris_wins <- results |> 
  filter(post_mean > 0) |> 
  summarize(
    ev_mean = sum(electoral_votes, na.rm = TRUE), 
    ev_se = sqrt(sum((post_sd * electoral_votes)^2, na.rm = TRUE)), 
    lower_CI = ev_mean - 1.96 * ev_se, 
    upper_CI = ev_mean + 1.96 * ev_se
  )

harris_wins
```

Harris received 226 electoral votes in the 2024 election. How did your model do? Provide some potential explanations for the performance.

```
YOUR SHORT ANSWER HERE
The model performed decently but underestimated Harris’ performance. Adjusting for polling biases, refining priors, and incorporating additional uncertainty could improve the model’s accuracy in future predictions.
```
